<!DOCTYPE html>
<html lang="en"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="OCR-VQA">
    <meta name="author" content="">

    <title>OCR-VQA</title>

    <link href="kvqa_ProjectFiles/bootstrap.css" rel="stylesheet">
    <link href="kvqa_ProjectFiles/style.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="js/html5shiv.js"></script>
      <script src="js/respond.min.js"></script>
    <![endif]-->
  </head>

  <body>

    <div class="container">
      <div class="header">
        <h1 class="text"><center>OCR-VQA: Visual Question Answering by Reading Text in Images</center></h1>
           <h4 class="text"><center>Anand Mishra, Shashank Shekhar, Ajeet Kumar Singh, Anirban Chakraborty</center></h4>
          <h4 class="text"><center>ICDAR 2019</center></h4>
          <h4 class="text"><center>[<a href="">PDF</a>]</center></h4>
       </div>

 <div class="container">
      <div class="header">
      <br>
<center>
<img src="kvqa_ProjectFiles/goal.jpg" height="500" border="1">
</center> 
&nbsp;
&nbsp;
&nbsp;
&nbsp;
Q: What is the title of this book? <br>
A: <font color="green">Vermont Beautiful</font><br>
Q: Who wrote this book? <br>
A: <font color="green">Wallace Nutting</font><br>
Q: What type of book is this?<br>
A: <font color="green">Travel</font>
</div>



      <div class="row">
        <h3>Motivation</h3>
        <p style="text-align: justify;">                   
The problem of answering questions about an
image is popularly known as visual question answering (or
VQA in short). It is a well-established problem in computer
vision. However, none of the VQA methods currently utilize the
text often present in the image. These “texts in images” provide
additional useful cues and facilitate better understanding of
the visual content. In this paper, we introduce a novel task of
visual question answering by reading text in images, i.e., by
optical character recognition or OCR. We refer to this problem
as OCR-VQA. To facilitate a systematic way of studying this
new problem, we introduce a large-scale dataset, namely
OCR-VQA–200K. This dataset comprises of 207,572 images of book
covers and contains more than 1 million question-answer pairs
about these images. We judiciously combine well-established
techniques from OCR and VQA to present a novel baseline
for OCR-VQA–200K. The experimental results and rigorous
analysis demonstrate various challenges present in this dataset
leaving ample scope for the future research. We are optimistic
that this new task along with compiled dataset will open-
up many exciting research avenues for the document image
analysis and VQA community
        </p>
      </div>
      <div class="row">
        <h3>Highlights</h3>
     <ul> 
      
     </ul>
               
     </div>


<div class="row">
         <h3 id="datasetE">Dataset: Explore</h3>
    <p>&nbsp;</p>
<table style="margin-left: auto; margin-right: auto;">
<tbody>
<tr>
<!-- <td><img style="margin-right: 10px; float: left;" src="" alt="I4" height="190" /></td> -->
</tr>
</tbody>
</table>
<a href=""> Explore more </a>

<div class="row">
         <h3 id="datasetD">Dataset: Downloads</h3>
        
            <div class="row">
<hr>


     
           


<h3><strong><span style="font-size: 12pt;">Bibtex</span></strong></h3>
<p>If you use this dataset, please cite:</p>
<pre><tt>@InProceedings{mishraICDAR19,
  author    = "Anand Mishra and Shashank Shekhar and Ajeet Kumar Singh and Anirban Chakraborty",
  title     = "OCR-VQA: Visual Question Answering by Reading Text in Images",
  booktitle = "ICDAR",
  year      = "2019",
}</tt></pre>
<hr>

        <h3>Publication</h3>
       <br>
Anand Mishra, Shashank Shekhar, Ajeet Kumar Singh, Anirban Chakraborty, <b>OCR-VQA: Visual Question Answering by Reading Text in Images</b>, ICDAR 2019
[<a href=""><u>pdf</u></a>][<a href=""><u>Abstract</u></a>][<a href="
"><u>Spotlight slides</u></a>] 

<br>
<br>


            
 <div class="row">
       <h3>People</h3>
        <a href="https://anandmishra22.github.io/"><u>Anand Mishra</u></a> <br>
        
      </div>


      <div class="row">
       <h3>Acknowledgements</h3>
        <p> Authors would like to thank MHRD, Govt. of India for partly supporting this work. 
        </p>
      </div>
      
      

    </div> <!-- /container -->


    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
  


</div></div></body></html>
